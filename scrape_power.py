import requests
import csv
import os
import sys
import time
from datetime import datetime

URL = "https://www.taipower.com.tw/d006/loadGraph/loadGraph/data/genary.json"
FILE_NAME = "power_history.csv"

def scrape():
    # ä½¿ç”¨ Session ä¾†è‡ªå‹•è™•ç† Cookie
    session = requests.Session()
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
        'Referer': 'https://www.taipower.com.tw/d006/loadGraph/loadGraph/genshx_.html',
        'Connection': 'keep-alive',
    }
    
    try:
        # å…ˆè¨ªå•ä¸»é é¢ä»¥å–å¾—æ½›åœ¨çš„ Session Cookie
        print("ğŸŒ æ­£åœ¨åˆå§‹åŒ–é€£ç·š...")
        session.get("https://www.taipower.com.tw/d006/loadGraph/loadGraph/genshx_.html", headers=headers, timeout=20)
        
        # ç¨å¾®ç­‰å¾… 2 ç§’ï¼Œæ¨¡æ“¬äººé¡è¡Œç‚º
        time.sleep(2)
        
        print("ğŸš€ æ­£åœ¨æå–ç™¼é›»æ•¸æ“š (aaData)...")
        response = session.get(URL, headers=headers, timeout=30)
        
        if response.status_code == 403:
            print("âŒ è¢«æ“‹ä½äº† (403 Forbidden)ã€‚å°é›»ä¼ºæœå™¨ç›®å‰æ‹’çµ•é€£ç·šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
            sys.exit(0) # é€™è£¡æ”¹ç”¨ exit(0) è®“ Workflow ä¸æœƒé¡¯ç¤ºç´…è‰²è­¦å ±ï¼Œå› ç‚ºé€™æ˜¯å¤–éƒ¨é™åˆ¶
            
        response.raise_for_status()
        data = response.json()
        
        # æŠ“å– aaData
        gens = data.get("aaData", [])
        if not gens:
            print("âš ï¸ è­¦å‘Šï¼šaaData ç‚ºç©ºï¼Œå¯èƒ½è³‡æ–™å°šæœªæ›´æ–°ã€‚")
            return

        update_time = datetime.now().strftime("%Y-%m-%d %H:%M")
        
        file_exists = os.path.isfile(FILE_NAME)
        with open(FILE_NAME, "a", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            if not file_exists:
                writer.writerow(["ç´€éŒ„æ™‚é–“", "é¡åˆ¥", "æ©Ÿçµ„", "ç™¼é›»é‡(MW)", "å‚™è¨»"])
            
            count = 0
            for item in gens:
                if isinstance(item, list) and len(item) >= 4:
                    # aaData ç´¢å¼•ï¼š1:é¡åˆ¥, 2:åç¨±, 3:ç™¼é›»é‡, 5:å‚™è¨»
                    writer.writerow([update_time, item[1], item[2], item[3], item[5] if len(item)>5 else ""])
                    count += 1
        
        print(f"âœ… æˆåŠŸå¯«å…¥ {count} ç­†è³‡æ–™åˆ° {FILE_NAME}")

    except Exception as e:
        print(f"âŒ åŸ·è¡Œç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    scrape()
