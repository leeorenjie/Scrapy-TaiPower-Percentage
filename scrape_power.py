import requests
import csv
import os
import sys
from datetime import datetime

# æ›´æ›ç‚ºå°é›»å®˜æ–¹è¡Œå‹•ç‰ˆ APIï¼Œé€šå¸¸è¼ƒä¸æ“‹ GitHub IP
URL = "https://www.taipower.com.tw/d006/loadGraph/loadGraph/data/genary.json"
FILE_NAME = "power_history.csv"

def scrape():
    headers = {
        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Mobile/15E148 Safari/604.1',
        'Accept': 'application/json'
    }
    
    try:
        print("ğŸŒ å˜—è©¦å­˜å–è¡Œå‹•ç‰ˆ API...")
        response = requests.get(URL, headers=headers, timeout=30)
        
        if response.status_code == 403:
            print("âŒ ä¾èˆŠè§¸ç™¼ 403ã€‚å°é›»ä¼ºæœå™¨æš«æ™‚å°é–äº† GitHub å€æ®µï¼Œè«‹å‹¿æ‰‹å‹•ç‹‚é»ï¼Œè®“å®ƒæ•´é»è‡ªå‹•åŸ·è¡Œå³å¯ã€‚")
            return

        response.raise_for_status()
        data = response.json()
        
        # æå–è³‡æ–™ï¼ˆå„ªå…ˆæ‰¾ aaDataï¼‰
        gens = data.get("aaData", [])
        if not gens:
            print("âš ï¸ æŠ“å–æˆåŠŸä½†è³‡æ–™å¤¾å…§ç„¡æ•¸æ“šã€‚")
            return

        update_time = datetime.now().strftime("%Y-%m-%d %H:%M")
        file_exists = os.path.isfile(FILE_NAME)
        
        with open(FILE_NAME, "a", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            if not file_exists or os.path.getsize(FILE_NAME) < 10:
                writer.writerow(["ç´€éŒ„æ™‚é–“", "é¡åˆ¥", "æ©Ÿçµ„", "ç™¼é›»é‡(MW)", "å‚™è¨»"])
            
            count = 0
            for item in gens:
                if len(item) >= 4:
                    # ç´¢å¼•å°æ‡‰ï¼š1:é¡åˆ¥, 2:åç¨±, 3:æ•¸å€¼
                    writer.writerow([update_time, item[1], item[2], item[3], item[5] if len(item)>5 else ""])
                    count += 1
        
        print(f"âœ… æ•¸æ“šæ›´æ–°æˆåŠŸï¼æœ¬æ¬¡å¯«å…¥ {count} ç­†ã€‚")

    except Exception as e:
        print(f"âŒ é€£ç·šç•°å¸¸: {str(e)}")

if __name__ == "__main__":
    scrape()
